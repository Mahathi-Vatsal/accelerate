# Copyright (c) 2024 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# SPDX-License-Identifier: Apache-2.0

apiVersion: batch/v1
kind: Job
metadata:
  name: accelerate-nlp  # Job name
spec:
  backoffLimit: 2  # The number of times k8s will retry a job that fails (this defaults to 6)
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: ipex-accelerate
        image: vault.habana.ai/gaudi-docker/1.19.0/ubuntu22.04/habanalabs/pytorch-installer-2.5.1:latest  # The name/tag of the docker image to use for the pod's container
        workingDir: /workspace
        command: ["/bin/bash", "-c"]
        args:  # Since this container does not have any scripts, we are cloning a repo, installing dependencies, and then running a script
          - >-
            apt-get update && apt-get install -y git;
            git clone https://github.com/huggingface/accelerate.git;
            cd accelerate;
            accelerate launch --mixed_precision fp16 --use_cpu true ./nlp_example.py;
        envFrom:
        - configMapRef:  # Specify the ConfigMap so that the proxy env vars are set in the container
            name: intel-proxy-config
        env:
        - name: TASK_NAME
          value: mrpc
        - name: OUTPUT_DIR
          value: /tmp/output
        resources:  # The resource limit/requests can be changed as you see fit for your job
            limits:
              cpu: 32
              memory: 32Gi
            requests:
              cpu: 32
              memory: 32Gi
